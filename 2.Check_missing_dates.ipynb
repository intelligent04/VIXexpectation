{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 파일에 포함된 날짜 개수: 4471\n",
      "어떤 파일에는 없지만, 다른 파일에는 포함된 날짜 개수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# processed_data 폴더 경로\n",
    "folder_path = \"./filtered_data\" ### 이게 filterd 데이터에서 가져오는게 맞아? 근데 processed 데이터로 바꾸면 밑에 어떤 파일에는 없지만, 다른 파일에는 포함된 날짜 개수가 몇 백개 생김\n",
    "\n",
    "# 모든 파일에서 포함된 날짜 저장\n",
    "date_counts = defaultdict(int)\n",
    "file_dates = {}\n",
    "\n",
    "# 파일 불러오기\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".csv\") or file.endswith(\".xlsx\"):  # CSV 또는 Excel 파일만 처리\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # 파일 형식에 따라 로드\n",
    "        if file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(file_path, parse_dates=[\"Date\"])\n",
    "        else:\n",
    "            df = pd.read_excel(file_path, parse_dates=[\"Date\"])\n",
    "        \n",
    "        # 날짜 열이 존재하는지 확인\n",
    "        if \"Date\" in df.columns:\n",
    "            unique_dates = set(df[\"Date\"].dt.date)\n",
    "            file_dates[file] = unique_dates\n",
    "            for date in unique_dates:\n",
    "                date_counts[date] += 1\n",
    "\n",
    "# 모든 파일에 포함된 날짜 개수\n",
    "total_files = len(file_dates)\n",
    "included_dates = sum(1 for count in date_counts.values() if count == total_files)\n",
    "excluded_dates = sum(1 for count in date_counts.values() if count != total_files)\n",
    "\n",
    "print(f\"모든 파일에 포함된 날짜 개수: {included_dates}\")\n",
    "print(f\"어떤 파일에는 없지만, 다른 파일에는 포함된 날짜 개수: {excluded_dates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어떤 파일에는 없지만, 다른 파일에는 포함된 날짜 목록:\n"
     ]
    }
   ],
   "source": [
    "# 누락된 날짜 확인 및 출력\n",
    "missing_dates = {date for date, count in date_counts.items() if count != total_files}\n",
    "missing_dates_per_file = {file: missing_dates - dates for file, dates in file_dates.items()}\n",
    "\n",
    "print(\"어떤 파일에는 없지만, 다른 파일에는 포함된 날짜 목록:\")\n",
    "for file, missing in missing_dates_per_file.items():\n",
    "    if missing:\n",
    "        print(f\"파일: {file}, 누락된 날짜: {sorted(missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주말 또는 공휴일인 누락 날짜 개수: 0\n",
      "주말 또는 공휴일이 아닌 누락 날짜 개수: 0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import holidays\n",
    "\n",
    "# 미국 공휴일 설정\n",
    "us_holidays = holidays.US()\n",
    "\n",
    "# 주말 및 공휴일 확인 함수\n",
    "def is_weekend_or_holiday(date):\n",
    "    return date.weekday() >= 5 or date in us_holidays  # 주말(토:5, 일:6) 또는 공휴일\n",
    "\n",
    "# 주말 또는 공휴일과 그렇지 않은 날짜 개수 세기\n",
    "weekend_or_holiday_count = sum(1 for date in missing_dates if is_weekend_or_holiday(date))\n",
    "non_weekend_or_holiday_count = len(missing_dates) - weekend_or_holiday_count\n",
    "\n",
    "print(f\"주말 또는 공휴일인 누락 날짜 개수: {weekend_or_holiday_count}\")\n",
    "print(f\"주말 또는 공휴일이 아닌 누락 날짜 개수: {non_weekend_or_holiday_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주말 또는 공휴일이 아닌 누락 날짜:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 주말 또는 공휴일이 아닌 누락 날짜 출력\n",
    "non_weekend_or_holiday_dates = [date for date in missing_dates if not is_weekend_or_holiday(date)]\n",
    "print(\"주말 또는 공휴일이 아닌 누락 날짜:\")\n",
    "print(sorted(non_weekend_or_holiday_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링된 데이터가 './filtered_data' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 원본 데이터 폴더 경로 및 저장할 폴더 경로 설정\n",
    "input_folder = \"./data\"\n",
    "output_folder = \"./filtered_data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 모든 파일에서 포함된 날짜 저장\n",
    "date_counts = {}\n",
    "file_dates = {}\n",
    "\n",
    "# 파일 불러오기\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\") or file.endswith(\".xlsx\"):  # CSV 또는 Excel 파일만 처리\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        \n",
    "        # 파일 형식에 따라 로드\n",
    "        if file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(file_path, parse_dates=[\"Date\"])\n",
    "        else:\n",
    "            df = pd.read_excel(file_path, parse_dates=[\"Date\"])\n",
    "        \n",
    "        # 날짜 열이 존재하는지 확인\n",
    "        if \"Date\" in df.columns:\n",
    "            unique_dates = set(df[\"Date\"].dt.date)\n",
    "            file_dates[file] = unique_dates\n",
    "            for date in unique_dates:\n",
    "                date_counts[date] = date_counts.get(date, 0) + 1\n",
    "\n",
    "# 모든 파일에 포함된 날짜 식별\n",
    "total_files = len(file_dates)\n",
    "included_dates = {date for date, count in date_counts.items() if count == total_files}\n",
    "\n",
    "# 모든 파일에서 포함되지 않은 날짜 제거 후 저장\n",
    "for file, dates in file_dates.items():\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    \n",
    "    # 파일 로드\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(file_path, parse_dates=[\"Date\"])\n",
    "    else:\n",
    "        df = pd.read_excel(file_path, parse_dates=[\"Date\"])\n",
    "    \n",
    "    # 날짜 필터링\n",
    "    df_filtered = df[df[\"Date\"].dt.date.isin(included_dates)]\n",
    "    \n",
    "    # 필터링된 파일 저장\n",
    "    output_path = os.path.join(output_folder, file)\n",
    "    if file.endswith(\".csv\"):\n",
    "        df_filtered.to_csv(output_path, index=False)\n",
    "    else:\n",
    "        df_filtered.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"필터링된 데이터가 '{output_folder}' 폴더에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "파일별 NaN 값 확인 결과:\n",
      "파일: Crude Oil WTI Futures Historical Data.csv - NaN 값 개수: 1\n",
      "파일: DIA ETF Stock Price History.csv - NaN 값 없음\n",
      "파일: Gold Futures Historical Data.csv - NaN 값 개수: 1\n",
      "파일: QQQ ETF Stock Price History.csv - NaN 값 없음\n",
      "파일: SPY ETF Stock Price History.csv - NaN 값 없음\n",
      "파일: United States 10-Year Bond Yield Historical Data.csv - NaN 값 없음\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"./filtered_data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 제외할 파일 목록\n",
    "exclude_files = {\"CBOE Volatility Index Historical Data.csv\", \"USD_KRW Historical Data.csv\"}\n",
    "\n",
    "# NaN 값 확인 (제외된 파일을 제외하고 검사)\n",
    "print(\"\\n파일별 NaN 값 확인 결과:\")\n",
    "for file in os.listdir(output_folder):\n",
    "    if file in exclude_files:\n",
    "        continue\n",
    "    \n",
    "    if file.endswith(\".csv\") or file.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(output_folder, file)\n",
    "        \n",
    "        # 파일 로드\n",
    "        if file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            df = pd.read_excel(file_path)\n",
    "        \n",
    "        # NaN 값 개수 확인\n",
    "        nan_count = df.isna().sum().sum()\n",
    "        if nan_count > 0:\n",
    "            print(f\"파일: {file} - NaN 값 개수: {nan_count}\")\n",
    "        else:\n",
    "            print(f\"파일: {file} - NaN 값 없음\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 파일에서 NaN이 포함된 날짜를 제거하고 저장 완료.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 원본 데이터 폴더 경로 및 저장할 폴더 경로 설정\n",
    "input_folder = \"./data\"\n",
    "output_folder = \"./filtered_data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 제외할 파일 목록 (VIX 및 환율 데이터는 NaN 검사에서 제외)\n",
    "exclude_files = {\"CBOE Volatility Index Historical Data.csv\", \"USD_KRW Historical Data.csv\"}\n",
    "\n",
    "# NaN 값이 포함된 날짜 찾기 (VIX 및 환율 데이터 제외하고 검사)\n",
    "nan_dates = set()\n",
    "for file in os.listdir(output_folder):\n",
    "    if file in exclude_files:\n",
    "        continue\n",
    "    \n",
    "    if file.endswith(\".csv\") or file.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(output_folder, file)\n",
    "        \n",
    "        # 파일 로드\n",
    "        if file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(file_path, parse_dates=[\"Date\"])\n",
    "        else:\n",
    "            df = pd.read_excel(file_path, parse_dates=[\"Date\"])\n",
    "        \n",
    "        # NaN이 있는 날짜 찾기\n",
    "        nan_rows = df[df.isna().any(axis=1)][\"Date\"].dt.date\n",
    "        nan_dates.update(nan_rows)\n",
    "\n",
    "# 모든 파일에서 NaN이 있는 날짜 제거 (VIX 및 환율 데이터 포함하여 처리)\n",
    "for file in os.listdir(output_folder):\n",
    "    if file.endswith(\".csv\") or file.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(output_folder, file)\n",
    "        \n",
    "        # 파일 로드\n",
    "        if file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(file_path, parse_dates=[\"Date\"])\n",
    "        else:\n",
    "            df = pd.read_excel(file_path, parse_dates=[\"Date\"])\n",
    "        \n",
    "        # NaN이 포함된 날짜 제거\n",
    "        df_filtered = df[~df[\"Date\"].dt.date.isin(nan_dates)]\n",
    "        \n",
    "        # 필터링된 파일 저장\n",
    "        if file.endswith(\".csv\"):\n",
    "            df_filtered.to_csv(file_path, index=False)\n",
    "        else:\n",
    "            df_filtered.to_excel(file_path, index=False)\n",
    "\n",
    "print(f\"모든 파일에서 NaN이 포함된 날짜를 제거하고 저장 완료.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuclear_bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
